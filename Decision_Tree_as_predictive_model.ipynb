{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"http://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-white.csv\", sep = ';')\n",
    "y = df.pop('quality')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.36</td>\n",
       "      <td>20.7</td>\n",
       "      <td>0.045</td>\n",
       "      <td>45.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>1.0010</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.45</td>\n",
       "      <td>8.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.3</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.34</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.049</td>\n",
       "      <td>14.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0.9940</td>\n",
       "      <td>3.30</td>\n",
       "      <td>0.49</td>\n",
       "      <td>9.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.1</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.40</td>\n",
       "      <td>6.9</td>\n",
       "      <td>0.050</td>\n",
       "      <td>30.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>0.9951</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.44</td>\n",
       "      <td>10.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.2</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.32</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.058</td>\n",
       "      <td>47.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>0.9956</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0.40</td>\n",
       "      <td>9.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.2</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.32</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.058</td>\n",
       "      <td>47.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>0.9956</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0.40</td>\n",
       "      <td>9.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0            7.0              0.27         0.36            20.7      0.045   \n",
       "1            6.3              0.30         0.34             1.6      0.049   \n",
       "2            8.1              0.28         0.40             6.9      0.050   \n",
       "3            7.2              0.23         0.32             8.5      0.058   \n",
       "4            7.2              0.23         0.32             8.5      0.058   \n",
       "\n",
       "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                 45.0                 170.0   1.0010  3.00       0.45   \n",
       "1                 14.0                 132.0   0.9940  3.30       0.49   \n",
       "2                 30.0                  97.0   0.9951  3.26       0.44   \n",
       "3                 47.0                 186.0   0.9956  3.19       0.40   \n",
       "4                 47.0                 186.0   0.9956  3.19       0.40   \n",
       "\n",
       "   alcohol  \n",
       "0      8.8  \n",
       "1      9.5  \n",
       "2     10.1  \n",
       "3      9.9  \n",
       "4      9.9  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6    2198\n",
       "5    1457\n",
       "7     880\n",
       "8     175\n",
       "4     163\n",
       "3      20\n",
       "9       5\n",
       "Name: quality, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in df.columns:\n",
    "    df[i] = df[i].fillna(np.mean(df[i]))\n",
    "train, test, y_train, y_test = train_test_split(df, y, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score baseline: 0.45918367346938777\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression()\n",
    "lr.fit(train, y_train)\n",
    "y_pred = lr.predict(test)\n",
    "print('Accuracy score baseline:', accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_predict(train, test, y_train, y_test, scaler, max_depth, \n",
    "                criterion = 'entropy', max_features = 1, min_samples_split = 4):\n",
    "    train_scaled = scaler.fit_transform(train)\n",
    "    test_scaled = scaler.transform(test)        \n",
    "    dt = DecisionTreeClassifier(criterion = criterion, max_depth=max_depth, \n",
    "                                random_state=42, max_features=max_features,\n",
    "                               min_samples_split=min_samples_split)\n",
    "    dt.fit(train_scaled, y_train)\n",
    "    y_pred = dt.predict(test_scaled)\n",
    "    print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6112244897959184\n"
     ]
    }
   ],
   "source": [
    "dt = DecisionTreeClassifier()\n",
    "dt.fit(train, y_train)\n",
    "y_pred = dt.predict(test)\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0   1   3   1   0   0   0]\n",
      " [  1   8   6   8   1   1   0]\n",
      " [  0  14 183  83   6   5   0]\n",
      " [  0   9  82 272  56  12   1]\n",
      " [  0   2   6  53 120  11   0]\n",
      " [  1   0   0   8   9  16   1]\n",
      " [  0   0   0   0   0   0   0]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           3       0.00      0.00      0.00         5\n",
      "           4       0.24      0.32      0.27        25\n",
      "           5       0.65      0.63      0.64       291\n",
      "           6       0.64      0.63      0.63       432\n",
      "           7       0.62      0.62      0.62       192\n",
      "           8       0.36      0.46      0.40        35\n",
      "           9       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.61       980\n",
      "   macro avg       0.36      0.38      0.37       980\n",
      "weighted avg       0.62      0.61      0.61       980\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Max depth tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score using max_depth = 1: 0.44081632653061226\n",
      "Accuracy score using max_depth = 2: 0.44081632653061226\n",
      "Accuracy score using max_depth = 3: 0.4530612244897959\n",
      "Accuracy score using max_depth = 4: 0.4602040816326531\n",
      "Accuracy score using max_depth = 5: 0.48673469387755103\n",
      "Accuracy score using max_depth = 6: 0.45918367346938777\n",
      "Accuracy score using max_depth = 7: 0.49795918367346936\n",
      "Accuracy score using max_depth = 8: 0.503061224489796\n",
      "Accuracy score using max_depth = 9: 0.5183673469387755\n",
      "Accuracy score using max_depth = 10: 0.4969387755102041\n",
      "Accuracy score using max_depth = 11: 0.5142857142857142\n",
      "Accuracy score using max_depth = 12: 0.49183673469387756\n",
      "Accuracy score using max_depth = 13: 0.576530612244898\n",
      "Accuracy score using max_depth = 14: 0.5714285714285714\n",
      "Accuracy score using max_depth = 15: 0.5336734693877551\n",
      "Accuracy score using max_depth = 16: 0.5489795918367347\n",
      "Accuracy score using max_depth = 17: 0.5520408163265306\n",
      "Accuracy score using max_depth = 18: 0.5775510204081633\n",
      "Accuracy score using max_depth = 19: 0.5612244897959183\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 20):\n",
    "    print('Accuracy score using max_depth =', i, end = ': ')\n",
    "    fit_predict(train, test, y_train, y_test, StandardScaler(), i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Max features tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score using max features = 0.1: 0.5775510204081633\n",
      "Accuracy score using max features = 0.2: 0.6112244897959184\n",
      "Accuracy score using max features = 0.30000000000000004: 0.6071428571428571\n",
      "Accuracy score using max features = 0.4: 0.5959183673469388\n",
      "Accuracy score using max features = 0.5: 0.6030612244897959\n",
      "Accuracy score using max features = 0.6: 0.5826530612244898\n",
      "Accuracy score using max features = 0.7000000000000001: 0.6020408163265306\n",
      "Accuracy score using max features = 0.8: 0.5724489795918367\n",
      "Accuracy score using max features = 0.9: 0.573469387755102\n"
     ]
    }
   ],
   "source": [
    "for i in np.arange(0.1, 1.0, 0.1):\n",
    "    print('Accuracy score using max features =', i, end = ': ')\n",
    "    fit_predict(train, test, y_train, y_test, StandardScaler(), max_depth = 18, max_features=i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Min samples split tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score using min samples split = 2: 0.6153061224489796\n",
      "Accuracy score using min samples split = 3: 0.5928571428571429\n",
      "Accuracy score using min samples split = 4: 0.6071428571428571\n",
      "Accuracy score using min samples split = 5: 0.5612244897959183\n",
      "Accuracy score using min samples split = 6: 0.5795918367346938\n",
      "Accuracy score using min samples split = 7: 0.563265306122449\n",
      "Accuracy score using min samples split = 8: 0.5938775510204082\n",
      "Accuracy score using min samples split = 9: 0.5540816326530612\n"
     ]
    }
   ],
   "source": [
    "for i in range(2, 10):\n",
    "    print('Accuracy score using min samples split =', i, end = ': ')\n",
    "    fit_predict(train, test, y_train, y_test, StandardScaler(), 18, max_features=0.3, min_samples_split=i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Criterion tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score using criterion = gini: 0.6153061224489796\n",
      "Accuracy score using criterion = entropy: 0.6153061224489796\n"
     ]
    }
   ],
   "source": [
    "for i in ['gini', 'entropy']:\n",
    "    print('Accuracy score using criterion =', i, end = ': ')\n",
    "    fit_predict(train, test, y_train, y_test, StandardScaler(), 18, \n",
    "                max_features=0.3, min_samples_split=2, criterion = 'entropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_poly(train,test,degree):\n",
    "    poly = PolynomialFeatures(degree=degree)\n",
    "    train_poly = poly.fit_transform(train)\n",
    "    test_poly = poly.fit_transform(test)\n",
    "    return train_poly,test_poly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train and Test samples shapes before degreed (3918, 15) (980, 15)\n",
      "Polynomial degree 1\n",
      "Train and Test samples shapes after degreed (3918, 16) (980, 16)\n",
      "0.5948979591836735\n",
      "----------\n",
      "Train and Test samples shapes before degreed (3918, 15) (980, 15)\n",
      "Polynomial degree 2\n",
      "Train and Test samples shapes after degreed (3918, 136) (980, 136)\n",
      "0.6173469387755102\n",
      "----------\n",
      "Train and Test samples shapes before degreed (3918, 15) (980, 15)\n",
      "Polynomial degree 3\n",
      "Train and Test samples shapes after degreed (3918, 816) (980, 816)\n",
      "0.5826530612244898\n",
      "----------\n",
      "Train and Test samples shapes before degreed (3918, 15) (980, 15)\n",
      "Polynomial degree 4\n",
      "Train and Test samples shapes after degreed (3918, 3876) (980, 3876)\n",
      "0.5979591836734693\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "for degree in [1,2,3,4]:\n",
    "    train_poly, test_poly = create_poly(train, test, degree)\n",
    "    print(\"Train and Test samples shapes before degreed\",train.shape,test.shape)\n",
    "    print('Polynomial degree',degree)\n",
    "    print(\"Train and Test samples shapes after degreed\",train_poly.shape,test_poly.shape)\n",
    "    fit_predict(train_poly, test_poly, y_train, y_test, StandardScaler(), 18, \n",
    "                max_features=0.3, min_samples_split=2, criterion = 'entropy')\n",
    "    print(10*'-')\n",
    "    \n",
    "train_poly, test_poly = create_poly(train, test, 2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Additional feature engineering:\n",
      "0.5938775510204082\n",
      "0.6173469387755102\n"
     ]
    }
   ],
   "source": [
    "def feat_eng(df):\n",
    "    df['eng1'] = df['fixed acidity'] * df['pH']\n",
    "    df['eng2'] = df['total sulfur dioxide'] / df['free sulfur dioxide']\n",
    "    df['eng3'] = df['sulphates'] / df['chlorides']\n",
    "    df['eng4'] = df['chlorides'] / df['sulphates']\n",
    "    return df\n",
    "\n",
    "train = feat_eng(train)\n",
    "test = feat_eng(test)\n",
    "\n",
    "print('Additional feature engineering:')\n",
    "\n",
    "fit_predict(train, test, y_train, y_test, StandardScaler(), 18, \n",
    "                max_features=0.3, min_samples_split=2, criterion = 'entropy')\n",
    "\n",
    "train_poly, test_poly = create_poly(train, test, 2)\n",
    "\n",
    "fit_predict(train_poly, test_poly, y_train, y_test, StandardScaler(), 18, \n",
    "                max_features=0.3, min_samples_split=2, criterion = 'entropy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overall improvement is 21.63 %\n"
     ]
    }
   ],
   "source": [
    "original_score = 0.514285714286\n",
    "best_score = 0.625510204082\n",
    "improvement = np.abs(np.round(100*(original_score - best_score)/original_score,2))\n",
    "print('overall improvement is {} %'.format(improvement))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
